{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imamuramasataka/Documents/kaggle/ashrae-energy-prediction/.venv/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import random\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "myfavouritenumber = 0\n",
    "seed = myfavouritenumber\n",
    "random.seed(seed)\n",
    "\n",
    "today = datetime.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "pd.set_option('max_rows', 9999)\n",
    "pd.set_option('max_columns', 9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half_Half_CatBoost Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, importance_df, model_type='lgb', use_feature_num=None):\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if use_feature_num is not None:\n",
    "            self.features = importance_df['feature'][:use_feature_num].tolist()\n",
    "        else:\n",
    "            self.features = None\n",
    "            \n",
    "    def train_half(self, X_train, y_train, params, num_boost_round, early_stopping_rounds, verbose=200):\n",
    "        \n",
    "        if self.features is None:\n",
    "            self.features = X_train.columns\n",
    "            \n",
    "        self.features = [c for c in self.features if c not in ['M']]\n",
    "            \n",
    "        self.X_train = X_train[self.features]\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        if self.model_type == 'lgb':\n",
    "            print('LightGBM Model Creating...')\n",
    "            d_half_1 = lgb.Dataset(self.X_train[:int(self.X_train.shape[0] / 2)], \n",
    "                                   label=self.y_train[:int(X_train.shape[0] / 2)])\n",
    "            d_half_2 = lgb.Dataset(self.X_train[int(self.X_train.shape[0] / 2):], \n",
    "                                   label=self.y_train[int(X_train.shape[0] / 2):])\n",
    "\n",
    "            print(\"Building model with first half and validating on second half:\")\n",
    "            self.model_1 = lgb.train(params, train_set=d_half_1, num_boost_round=num_boost_round, \n",
    "                                     valid_sets=[d_half_1, d_half_2], verbose_eval=verbose, \n",
    "                                     early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            print('')\n",
    "            print(\"Building model with second half and validating on first half:\")\n",
    "            self.model_2 = lgb.train(params, train_set=d_half_2, num_boost_round=num_boost_round, \n",
    "                                     valid_sets=[d_half_2, d_half_1], verbose_eval=verbose, \n",
    "                                     early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "        elif self.model_type == 'cat':\n",
    "            print('CatBoost Model Creating...')\n",
    "            cat_features_index = np.where(self.X_train.dtypes == 'category')[0]\n",
    "            d_half_1 = Pool(self.X_train[:int(self.X_train.shape[0] / 2)], \n",
    "                            label=self.y_train[:int(X_train.shape[0] / 2)],\n",
    "                            cat_features=cat_features_index)\n",
    "            d_half_2 = Pool(self.X_train[int(self.X_train.shape[0] / 2):], \n",
    "                            label=self.y_train[int(X_train.shape[0] / 2):],\n",
    "                            cat_features=cat_features_index)\n",
    "            \n",
    "            params['iterations'] = num_boost_round\n",
    "            print(\"Building model with first half and validating on second half:\")\n",
    "            self.model_1 = CatBoostRegressor(**params)\n",
    "            self.model_1.fit(d_half_1, eval_set=d_half_2, use_best_model=True,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose=verbose)\n",
    "            \n",
    "            print('')\n",
    "            print(\"Building model with second half and validating on first half:\")\n",
    "            self.model_2 = CatBoostRegressor(**params)\n",
    "            self.model_2.fit(d_half_2, eval_set=d_half_1, use_best_model=True,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose=verbose)\n",
    "            \n",
    "        \n",
    "        return (self.model_1, self.model_2)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        df_fimp_1 = pd.DataFrame()\n",
    "        df_fimp_1[\"feature\"] = self.X_train.columns.values\n",
    "        if self.model_type == 'lgb':\n",
    "            df_fimp_1[\"importance\"] = self.model_1.feature_importance()\n",
    "        elif self.model_type == 'cat':\n",
    "            df_fimp_1[\"importance\"] = self.model_1.get_feature_importance()\n",
    "        df_fimp_1[\"half\"] = 1\n",
    "\n",
    "        df_fimp_2 = pd.DataFrame()\n",
    "        df_fimp_2[\"feature\"] = self.X_train.columns.values\n",
    "        if self.model_type == 'lgb':\n",
    "            df_fimp_2[\"importance\"] = self.model_2.feature_importance()\n",
    "        elif self.model_type == 'cat':\n",
    "            df_fimp_2[\"importance\"] = self.model_2.get_feature_importance()\n",
    "        df_fimp_2[\"half\"] = 2\n",
    "\n",
    "        df_fimp = pd.concat([df_fimp_1, df_fimp_2], axis=0)\n",
    "\n",
    "        plt.figure(figsize=(14, int(len(self.X_train.columns) * 0.3)), facecolor='w')\n",
    "        sns.barplot(x=\"importance\", y=\"feature\", data=df_fimp.sort_values(by=\"importance\", ascending=False))\n",
    "        plt.title(\"CatBoost Feature Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        del df_fimp_1, df_fimp_2, df_fimp\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config - CatBoost\n",
    "train_pkl_path = '../input/prep_train_20191125.pkl'\n",
    "test_pkl_path = '../input/prep_test_20191125.pkl'\n",
    "importance_path = '../Importance/importance_20191125.csv'\n",
    "model_type = 'cat'\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'loss_function': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'metric_period': 10,\n",
    "    'task_type': 'CPU',\n",
    "    'depth': 8,\n",
    "    }\n",
    "\n",
    "num_boost_round = 5000\n",
    "early_stopping_rounds = 50\n",
    "num_feature = 30\n",
    "verbose = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Model Creating...\n",
      "Building model with first half and validating on second half:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.8644602\ttest: 1.8752131\tbest: 1.8752131 (0)\ttotal: 18.4s\tremaining: 1d 1h 31m 36s\n",
      "10:\tlearn: 1.2377231\ttest: 1.3838277\tbest: 1.3838277 (10)\ttotal: 2m 6s\tremaining: 15h 59m 16s\n",
      "20:\tlearn: 1.1533503\ttest: 1.3277849\tbest: 1.3277849 (20)\ttotal: 4m 30s\tremaining: 17h 47m 50s\n",
      "30:\tlearn: 1.1133774\ttest: 1.3142855\tbest: 1.3142855 (30)\ttotal: 7m 3s\tremaining: 18h 52m 22s\n",
      "40:\tlearn: 1.0808643\ttest: 1.2959109\tbest: 1.2959109 (40)\ttotal: 10m 5s\tremaining: 20h 19m 35s\n",
      "50:\tlearn: 1.0590698\ttest: 1.2858617\tbest: 1.2858617 (50)\ttotal: 12m 42s\tremaining: 20h 33m 43s\n",
      "60:\tlearn: 1.0384592\ttest: 1.2773253\tbest: 1.2773253 (60)\ttotal: 15m 16s\tremaining: 20h 36m 43s\n",
      "70:\tlearn: 1.0208796\ttest: 1.2694154\tbest: 1.2694154 (70)\ttotal: 18m 18s\tremaining: 21h 11m 32s\n",
      "80:\tlearn: 1.0057805\ttest: 1.2626994\tbest: 1.2626994 (80)\ttotal: 21m 23s\tremaining: 21h 39m 27s\n",
      "90:\tlearn: 0.9928790\ttest: 1.2571561\tbest: 1.2571561 (90)\ttotal: 24m 8s\tremaining: 21h 42m 10s\n",
      "100:\tlearn: 0.9826615\ttest: 1.2510237\tbest: 1.2510237 (100)\ttotal: 26m 52s\tremaining: 21h 43m 13s\n",
      "110:\tlearn: 0.9717840\ttest: 1.2483570\tbest: 1.2483570 (110)\ttotal: 29m 44s\tremaining: 21h 49m 53s\n",
      "120:\tlearn: 0.9623398\ttest: 1.2440704\tbest: 1.2440704 (120)\ttotal: 32m 26s\tremaining: 21h 47m 50s\n",
      "130:\tlearn: 0.9547178\ttest: 1.2427697\tbest: 1.2427697 (130)\ttotal: 35m 27s\tremaining: 21h 57m 51s\n",
      "140:\tlearn: 0.9465455\ttest: 1.2403444\tbest: 1.2403444 (140)\ttotal: 38m 25s\tremaining: 22h 4m 19s\n",
      "150:\tlearn: 0.9361589\ttest: 1.2353202\tbest: 1.2349954 (149)\ttotal: 41m 26s\tremaining: 22h 10m 39s\n",
      "160:\tlearn: 0.9302241\ttest: 1.2332803\tbest: 1.2332803 (160)\ttotal: 44m 28s\tremaining: 22h 16m 45s\n",
      "170:\tlearn: 0.9240381\ttest: 1.2321093\tbest: 1.2308910 (168)\ttotal: 47m 31s\tremaining: 22h 22m 16s\n",
      "180:\tlearn: 0.9191697\ttest: 1.2303741\tbest: 1.2303741 (180)\ttotal: 50m 44s\tremaining: 22h 30m 57s\n",
      "190:\tlearn: 0.9127940\ttest: 1.2292471\tbest: 1.2288704 (189)\ttotal: 53m 57s\tremaining: 22h 38m 44s\n",
      "200:\tlearn: 0.9064126\ttest: 1.2264615\tbest: 1.2264615 (200)\ttotal: 56m 58s\tremaining: 22h 40m 18s\n",
      "210:\tlearn: 0.9021444\ttest: 1.2268210\tbest: 1.2261604 (202)\ttotal: 59m 47s\tremaining: 22h 37m 1s\n",
      "220:\tlearn: 0.8972188\ttest: 1.2250740\tbest: 1.2250740 (220)\ttotal: 1h 2m 41s\tremaining: 22h 35m 49s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2aefb099c0b0>\u001b[0m in \u001b[0;36mtrain_half\u001b[0;34m(self, X_train, y_train, params, num_boost_round, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m             self.model_1.fit(d_half_1, eval_set=d_half_2, use_best_model=True,\n\u001b[1;32m     52\u001b[0m                         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                         verbose=verbose)\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/kaggle/ashrae-energy-prediction/.venv/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   4138\u001b[0m                          \u001b[0muse_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4139\u001b[0m                          \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4140\u001b[0;31m                          save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[1;32m   4141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/kaggle/ashrae-energy-prediction/.venv/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[1;32m   1616\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m             )\n\u001b[1;32m   1620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/kaggle/ashrae-energy-prediction/.venv/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "# Data Loading\n",
    "with open(train_pkl_path, 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "importance_df = pd.read_csv(importance_path)\n",
    "# Train Model\n",
    "trainer = Trainer(importance_df=importance_df, model_type=model_type, use_feature_num=num_feature)\n",
    "models = trainer.train_half(train[0], train[1], params, num_boost_round, early_stopping_rounds, verbose)\n",
    "\n",
    "del train, importance_df\n",
    "gc.collect()\n",
    "\n",
    "with open(f'../Model/model_{today}_{trainer.model_type}_half.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing test data \n",
    "\n",
    "Preparing test data with same features as train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Predict & Submission\n",
    "\n",
    "# Data Loading\n",
    "with open(test_pkl_path, 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_test = test[0]\n",
    "row_id = test[1]\n",
    "del test\n",
    "gc.collect()\n",
    "    \n",
    "if num_feature is not None:\n",
    "    X_test = X_test[trainer.features]\n",
    "    gc.collect()\n",
    "\n",
    "# Set Predict values\n",
    "pred = np.zeros(len(row_id))\n",
    "\n",
    "# Prediction\n",
    "for model in models:\n",
    "    if trainer.model_type == 'lgb':\n",
    "        pred += np.expm1(model.predict(X_test, num_iteration=model.best_iteration)) / int(len(models))\n",
    "    elif trainer.model_type == 'cat':\n",
    "        pred += np.expm1(model.predict(X_test)) / int(len(models))\n",
    "    \n",
    "today = datetime.datetime.now().strftime('%Y%m%d')\n",
    "submission = pd.DataFrame({\"row_id\": row_id, \"meter_reading\": np.clip(pred, 0, a_max=None)})\n",
    "submission.to_csv(f\"../Output/submission_from_nb_{trainer.model_type}_{today}.csv\", index=False)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
