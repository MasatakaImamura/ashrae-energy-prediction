{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import random\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "myfavouritenumber = 0\n",
    "seed = myfavouritenumber\n",
    "random.seed(seed)\n",
    "\n",
    "today = datetime.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "pd.set_option('max_rows', 9999)\n",
    "pd.set_option('max_columns', 9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half_Half_CatBoost Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, importance_df, model_type='lgb', use_feature_num=None):\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if use_feature_num is not None:\n",
    "            self.features = importance_df['feature'][:use_feature_num].tolist()\n",
    "        else:\n",
    "            self.features = None\n",
    "            \n",
    "    def train_half(self, X_train, y_train, params, num_boost_round, early_stopping_rounds, verbose=200):\n",
    "        \n",
    "        if self.features is None:\n",
    "            self.features = X_train.columns\n",
    "            \n",
    "        self.features = [c for c in self.features if c not in ['M']]\n",
    "            \n",
    "        self.X_train = X_train[self.features]\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        if self.model_type == 'lgb':\n",
    "            print('LightGBM Model Creating...')\n",
    "            d_half_1 = lgb.Dataset(self.X_train[:int(self.X_train.shape[0] / 2)], \n",
    "                                   label=self.y_train[:int(X_train.shape[0] / 2)])\n",
    "            d_half_2 = lgb.Dataset(self.X_train[int(self.X_train.shape[0] / 2):], \n",
    "                                   label=self.y_train[int(X_train.shape[0] / 2):])\n",
    "\n",
    "            print(\"Building model with first half and validating on second half:\")\n",
    "            self.model_1 = lgb.train(params, train_set=d_half_1, num_boost_round=num_boost_round, \n",
    "                                     valid_sets=[d_half_1, d_half_2], verbose_eval=verbose, \n",
    "                                     early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            print('')\n",
    "            print(\"Building model with second half and validating on first half:\")\n",
    "            self.model_2 = lgb.train(params, train_set=d_half_2, num_boost_round=num_boost_round, \n",
    "                                     valid_sets=[d_half_2, d_half_1], verbose_eval=verbose, \n",
    "                                     early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "        elif self.model_type == 'cat':\n",
    "            print('CatBoost Model Creating...')\n",
    "            cat_features_index = np.where(self.X_train.dtypes == 'category')[0]\n",
    "            d_half_1 = Pool(self.X_train[:int(self.X_train.shape[0] / 2)], \n",
    "                            label=self.y_train[:int(X_train.shape[0] / 2)],\n",
    "                            cat_features=cat_features_index)\n",
    "            d_half_2 = Pool(self.X_train[int(self.X_train.shape[0] / 2):], \n",
    "                            label=self.y_train[int(X_train.shape[0] / 2):],\n",
    "                            cat_features=cat_features_index)\n",
    "            \n",
    "            params['iterations'] = num_boost_round\n",
    "            print(\"Building model with first half and validating on second half:\")\n",
    "            self.model_1 = CatBoostRegressor(**params)\n",
    "            self.model_1.fit(d_half_1, eval_set=d_half_2, use_best_model=True,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose=verbose)\n",
    "            \n",
    "            print('')\n",
    "            print(\"Building model with second half and validating on first half:\")\n",
    "            self.model_2 = CatBoostRegressor(**params)\n",
    "            self.model_2.fit(d_half_2, eval_set=d_half_1, use_best_model=True,\n",
    "                        early_stopping_rounds=early_stopping_rounds,\n",
    "                        verbose=verbose)\n",
    "            \n",
    "        \n",
    "        return (self.model_1, self.model_2)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        df_fimp_1 = pd.DataFrame()\n",
    "        df_fimp_1[\"feature\"] = self.X_train.columns.values\n",
    "        if self.model_type == 'lgb':\n",
    "            df_fimp_1[\"importance\"] = self.model_1.feature_importance()\n",
    "        elif self.model_type == 'cat':\n",
    "            df_fimp_1[\"importance\"] = self.model_1.get_feature_importance()\n",
    "        df_fimp_1[\"half\"] = 1\n",
    "\n",
    "        df_fimp_2 = pd.DataFrame()\n",
    "        df_fimp_2[\"feature\"] = self.X_train.columns.values\n",
    "        if self.model_type == 'lgb':\n",
    "            df_fimp_2[\"importance\"] = self.model_2.feature_importance()\n",
    "        elif self.model_type == 'cat':\n",
    "            df_fimp_2[\"importance\"] = self.model_2.get_feature_importance()\n",
    "        df_fimp_2[\"half\"] = 2\n",
    "\n",
    "        df_fimp = pd.concat([df_fimp_1, df_fimp_2], axis=0)\n",
    "\n",
    "        plt.figure(figsize=(14, int(len(self.X_train.columns) * 0.3)), facecolor='w')\n",
    "        sns.barplot(x=\"importance\", y=\"feature\", data=df_fimp.sort_values(by=\"importance\", ascending=False))\n",
    "        plt.title(\"LightGBM Feature Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        del df_fimp_1, df_fimp_2, df_fimp\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config - CatBoost\n",
    "train_pkl_path = '../input/prep_train_20191118.pkl'\n",
    "test_pkl_path = '../input/prep_test_20191118.pkl'\n",
    "importance_path = '../Importance/importance_20191118.csv'\n",
    "model_type = 'cat'\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.2,\n",
    "    'eval_metric': 'RMSE',\n",
    "    'loss_function': 'RMSE',\n",
    "    'random_seed': 42,\n",
    "    'metric_period': 10,\n",
    "    'task_type': 'GPU',\n",
    "    'depth': 8,\n",
    "    }\n",
    "\n",
    "num_boost_round = 5000\n",
    "early_stopping_rounds = 50\n",
    "num_feature = 30\n",
    "verbose = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Model Creating...\n",
      "Building model with first half and validating on second half:\n",
      "0:\tlearn: 1.8622536\ttest: 1.8715138\tbest: 1.8715138 (0)\ttotal: 1.32s\tremaining: 1h 50m 12s\n",
      "10:\tlearn: 1.2042169\ttest: 1.3491464\tbest: 1.3491464 (10)\ttotal: 15.7s\tremaining: 1h 58m 28s\n",
      "20:\tlearn: 1.1221547\ttest: 1.2949159\tbest: 1.2949159 (20)\ttotal: 29s\tremaining: 1h 54m 43s\n",
      "30:\tlearn: 1.0808984\ttest: 1.2752895\tbest: 1.2752895 (30)\ttotal: 42.8s\tremaining: 1h 54m 24s\n",
      "40:\tlearn: 1.0502876\ttest: 1.2661738\tbest: 1.2645974 (39)\ttotal: 56.6s\tremaining: 1h 54m 9s\n",
      "50:\tlearn: 1.0275786\ttest: 1.2576084\tbest: 1.2561018 (48)\ttotal: 1m 11s\tremaining: 1h 55m 30s\n",
      "60:\tlearn: 1.0063694\ttest: 1.2478171\tbest: 1.2478171 (60)\ttotal: 1m 27s\tremaining: 1h 58m 23s\n",
      "70:\tlearn: 0.9878811\ttest: 1.2457145\tbest: 1.2457145 (70)\ttotal: 1m 43s\tremaining: 1h 59m 12s\n",
      "80:\tlearn: 0.9740204\ttest: 1.2376162\tbest: 1.2376162 (80)\ttotal: 1m 58s\tremaining: 1h 59m 34s\n",
      "90:\tlearn: 0.9603594\ttest: 1.2353070\tbest: 1.2347004 (87)\ttotal: 2m 13s\tremaining: 1h 59m 53s\n",
      "100:\tlearn: 0.9470377\ttest: 1.2336391\tbest: 1.2329833 (96)\ttotal: 2m 27s\tremaining: 1h 59m 22s\n",
      "110:\tlearn: 0.9369475\ttest: 1.2288440\tbest: 1.2288440 (110)\ttotal: 2m 43s\tremaining: 1h 59m 49s\n",
      "120:\tlearn: 0.9266283\ttest: 1.2251303\tbest: 1.2251303 (120)\ttotal: 3m\tremaining: 2h 1m 15s\n",
      "130:\tlearn: 0.9167294\ttest: 1.2218765\tbest: 1.2214852 (129)\ttotal: 3m 16s\tremaining: 2h 1m 43s\n",
      "140:\tlearn: 0.9085483\ttest: 1.2202916\tbest: 1.2202916 (140)\ttotal: 3m 32s\tremaining: 2h 2m 19s\n",
      "150:\tlearn: 0.9006638\ttest: 1.2201191\tbest: 1.2201191 (150)\ttotal: 3m 47s\tremaining: 2h 1m 59s\n",
      "160:\tlearn: 0.8948040\ttest: 1.2169195\tbest: 1.2169195 (160)\ttotal: 4m 3s\tremaining: 2h 1m 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "# Data Loading\n",
    "with open(train_pkl_path, 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "importance_df = pd.read_csv(importance_path)\n",
    "# Train Model\n",
    "trainer = Trainer(importance_df=importance_df, model_type=model_type, use_feature_num=num_feature)\n",
    "models = trainer.train_half(train[0], train[1], params, num_boost_round, early_stopping_rounds, verbose)\n",
    "\n",
    "del train, importance_df\n",
    "gc.collect()\n",
    "\n",
    "with open(f'../Model/model_{today}_{trainer.model_type}_half.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.get_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing test data \n",
    "\n",
    "Preparing test data with same features as train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Predict & Submission\n",
    "\n",
    "# Data Loading\n",
    "with open(test_pkl_path, 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_test = test[0]\n",
    "row_id = test[1]\n",
    "del test\n",
    "gc.collect()\n",
    "    \n",
    "if num_feature is not None:\n",
    "    X_test = X_test[trainer.features]\n",
    "    gc.collect()\n",
    "\n",
    "# Set Predict values\n",
    "pred = np.zeros(len(row_id))\n",
    "\n",
    "# Prediction\n",
    "for model in models:\n",
    "    if trainer.model_type == 'lgb':\n",
    "        pred += np.expm1(model.predict(X_test, num_iteration=model.best_iteration)) / int(len(models))\n",
    "    elif trainer.model_type == 'cat':\n",
    "        pred += np.expm1(model.predict(X_test)) / int(len(models))\n",
    "    \n",
    "today = datetime.datetime.now().strftime('%Y%m%d')\n",
    "submission = pd.DataFrame({\"row_id\": row_id, \"meter_reading\": np.clip(pred, 0, a_max=None)})\n",
    "submission.to_csv(f\"../Output/submission_from_nb_{trainer.model_type}_{today}.csv\", index=False)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
