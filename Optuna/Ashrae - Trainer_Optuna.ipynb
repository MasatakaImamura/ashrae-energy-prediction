{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import random\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import optuna\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "myfavouritenumber = 0\n",
    "seed = myfavouritenumber\n",
    "random.seed(seed)\n",
    "\n",
    "pd.set_option('max_rows', 9999)\n",
    "pd.set_option('max_columns', 9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half_Half_LightGBM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, importance_df, model_type='lgb', use_feature_num=None):\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if use_feature_num is not None:\n",
    "            self.features = importance_df['feature'][:use_feature_num].tolist()\n",
    "        else:\n",
    "            self.features = None\n",
    "            \n",
    "    def train_half_optuna(self, X_train, y_train, params, num_boost_round, early_stopping_rounds, verbose=200, trial=None):\n",
    "        \n",
    "        if self.features is None:\n",
    "            self.features = X_train.columns\n",
    "            \n",
    "        self.features = [c for c in self.features if c not in ['M']]\n",
    "            \n",
    "        self.X_train = X_train[self.features]\n",
    "        self.y_train = y_train\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'rmse')\n",
    "        \n",
    "        if self.model_type == 'lgb':\n",
    "            d_half_1 = lgb.Dataset(self.X_train[:int(self.X_train.shape[0] / 2)], \n",
    "                                   label=self.y_train[:int(X_train.shape[0] / 2)])\n",
    "            d_half_2 = lgb.Dataset(self.X_train[int(self.X_train.shape[0] / 2):], \n",
    "                                   label=self.y_train[int(X_train.shape[0] / 2):])\n",
    "\n",
    "            self.model_1 = lgb.train(params, train_set=d_half_1, num_boost_round=num_boost_round, \n",
    "                                     valid_sets=[d_half_2], verbose_eval=verbose, \n",
    "                                     early_stopping_rounds=early_stopping_rounds, \n",
    "                                     callbacks=[pruning_callback])\n",
    "            \n",
    "            oof = self.model_1.predict(self.X_train[int(self.X_train.shape[0] / 2):],\n",
    "                                       num_iteration=self.model_1.best_iteration)\n",
    "            oof = np.clip(oof, 0, a_max=None)\n",
    "            \n",
    "            rmse = np.sqrt(mean_squared_error(self.y_train[int(X_train.shape[0] / 2):], oof))\n",
    "            \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "train_pkl_path = '../input/prep_train_20191118.pkl'\n",
    "test_pkl_path = '../input/prep_test_20191118.pkl'\n",
    "importance_path = '../Importance/importance_20191118.csv'\n",
    "model_type = 'lgb'\n",
    "\n",
    "# Create SQLite Table\n",
    "con = sqlite3.connect('ashrae_lgb.db')\n",
    "\n",
    "def objective(trial):\n",
    "    # Search Parameter Range\n",
    "    set_lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbrt',\n",
    "        'metric': 'rmse',\n",
    "        'n_jobs': -1,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_bin': 255,\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 10),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 100, 300),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 0.9),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 0.9),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.3, 0.9),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.3, 0.9),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 20),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-2, 1e+3),\n",
    "        'verbose': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    num_boost_round = 1000\n",
    "    early_stopping_rounds = 50\n",
    "    num_feature = 30\n",
    "    verbose = False\n",
    "    \n",
    "    # Train Model\n",
    "    trainer = Trainer(importance_df=importance_df, model_type=model_type, use_feature_num=num_feature)\n",
    "    rmse = trainer.train_half_optuna(train[0], train[1], set_lgb_params, num_boost_round, \n",
    "                                       early_stopping_rounds, verbose, trial)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-11-20 20:14:42,754] Using an existing study with name 'ashrae_lgb' instead of creating a new one.\n",
      "[I 2019-11-20 20:15:38,723] Setting status of trial#108 as TrialState.PRUNED. Trial was pruned at iteration 50.\n",
      "[I 2019-11-20 20:18:05,075] Setting status of trial#109 as TrialState.PRUNED. Trial was pruned at iteration 200.\n",
      "[I 2019-11-20 20:38:17,677] Finished trial#110 resulted in value: 1.1418521030771662. Current best value is 1.1378703133301726 with parameters: {'bagging_fraction': 0.42797307400289963, 'bagging_freq': 6, 'colsample_bytree': 0.8659940184256816, 'feature_fraction': 0.852216419174993, 'max_depth': 10, 'min_data_in_leaf': 47, 'num_leaves': 242, 'reg_lambda': 137.8767751523373, 'subsample': 0.8922113062563624}.\n",
      "[I 2019-11-20 20:48:39,316] Setting status of trial#111 as TrialState.PRUNED. Trial was pruned at iteration 800.\n",
      "[I 2019-11-20 20:49:26,597] Setting status of trial#112 as TrialState.PRUNED. Trial was pruned at iteration 50.\n",
      "[I 2019-11-20 20:59:51,181] Setting status of trial#113 as TrialState.PRUNED. Trial was pruned at iteration 800.\n",
      "[I 2019-11-20 21:02:36,883] Setting status of trial#114 as TrialState.PRUNED. Trial was pruned at iteration 200.\n",
      "[I 2019-11-20 21:05:33,301] Setting status of trial#115 as TrialState.PRUNED. Trial was pruned at iteration 200.\n",
      "[I 2019-11-20 21:24:01,807] Finished trial#116 resulted in value: 1.1403990800980468. Current best value is 1.1378703133301726 with parameters: {'bagging_fraction': 0.42797307400289963, 'bagging_freq': 6, 'colsample_bytree': 0.8659940184256816, 'feature_fraction': 0.852216419174993, 'max_depth': 10, 'min_data_in_leaf': 47, 'num_leaves': 242, 'reg_lambda': 137.8767751523373, 'subsample': 0.8922113062563624}.\n",
      "[I 2019-11-20 21:43:24,167] Finished trial#117 resulted in value: 1.1403171336385. Current best value is 1.1378703133301726 with parameters: {'bagging_fraction': 0.42797307400289963, 'bagging_freq': 6, 'colsample_bytree': 0.8659940184256816, 'feature_fraction': 0.852216419174993, 'max_depth': 10, 'min_data_in_leaf': 47, 'num_leaves': 242, 'reg_lambda': 137.8767751523373, 'subsample': 0.8922113062563624}.\n",
      "[I 2019-11-20 22:02:39,616] Finished trial#118 resulted in value: 1.141621954257156. Current best value is 1.1378703133301726 with parameters: {'bagging_fraction': 0.42797307400289963, 'bagging_freq': 6, 'colsample_bytree': 0.8659940184256816, 'feature_fraction': 0.852216419174993, 'max_depth': 10, 'min_data_in_leaf': 47, 'num_leaves': 242, 'reg_lambda': 137.8767751523373, 'subsample': 0.8922113062563624}.\n",
      "[I 2019-11-20 22:12:51,312] Setting status of trial#119 as TrialState.PRUNED. Trial was pruned at iteration 800.\n",
      "[I 2019-11-20 22:13:31,116] Setting status of trial#120 as TrialState.PRUNED. Trial was pruned at iteration 50.\n",
      "[I 2019-11-20 22:32:59,901] Finished trial#121 resulted in value: 1.1397478280735687. Current best value is 1.1378703133301726 with parameters: {'bagging_fraction': 0.42797307400289963, 'bagging_freq': 6, 'colsample_bytree': 0.8659940184256816, 'feature_fraction': 0.852216419174993, 'max_depth': 10, 'min_data_in_leaf': 47, 'num_leaves': 242, 'reg_lambda': 137.8767751523373, 'subsample': 0.8922113062563624}.\n",
      "[I 2019-11-20 22:35:45,239] Setting status of trial#122 as TrialState.PRUNED. Trial was pruned at iteration 200.\n",
      "[I 2019-11-20 22:36:39,749] Setting status of trial#123 as TrialState.PRUNED. Trial was pruned at iteration 50.\n",
      "[I 2019-11-20 22:46:28,940] Setting status of trial#124 as TrialState.PRUNED. Trial was pruned at iteration 800.\n",
      "[I 2019-11-20 22:47:23,785] Setting status of trial#125 as TrialState.PRUNED. Trial was pruned at iteration 50.\n",
      "[I 2019-11-20 22:48:15,694] Setting status of trial#126 as TrialState.PRUNED. Trial was pruned at iteration 50.\n",
      "[I 2019-11-20 22:50:48,063] Setting status of trial#127 as TrialState.PRUNED. Trial was pruned at iteration 200.\n",
      "[I 2019-11-20 22:51:33,290] Setting status of trial#128 as TrialState.PRUNED. Trial was pruned at iteration 50.\n",
      "[I 2019-11-20 23:11:21,522] Finished trial#129 resulted in value: 1.1405374745476784. Current best value is 1.1378703133301726 with parameters: {'bagging_fraction': 0.42797307400289963, 'bagging_freq': 6, 'colsample_bytree': 0.8659940184256816, 'feature_fraction': 0.852216419174993, 'max_depth': 10, 'min_data_in_leaf': 47, 'num_leaves': 242, 'reg_lambda': 137.8767751523373, 'subsample': 0.8922113062563624}.\n",
      "[I 2019-11-20 23:12:13,875] Setting status of trial#130 as TrialState.PRUNED. Trial was pruned at iteration 50.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7030602738e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\python\\kaggle\\ashrae~1\\venv~1\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 self._optimize_sequential(func, n_trials, timeout, catch, callbacks,\n\u001b[1;32m--> 261\u001b[1;33m                                           gc_after_trial)\n\u001b[0m\u001b[0;32m    262\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m                 self._optimize_parallel(func, n_trials, timeout, n_jobs, catch, callbacks,\n",
      "\u001b[1;32md:\\python\\kaggle\\ashrae~1\\venv~1\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     def _optimize_parallel(\n",
      "\u001b[1;32md:\\python\\kaggle\\ashrae~1\\venv~1\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# type: (...) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\kaggle\\ashrae~1\\venv~1\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             message = 'Setting status of trial#{} as {}. {}'.format(trial_number,\n",
      "\u001b[1;32m<ipython-input-3-78e35594dba9>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimportance_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_feature_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     rmse = trainer.train_half_optuna(train[0], train[1], set_lgb_params, num_boost_round, \n\u001b[1;32m---> 40\u001b[1;33m                                        early_stopping_rounds, verbose, trial)\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e972ed8552a7>\u001b[0m in \u001b[0;36mtrain_half_optuna\u001b[1;34m(self, X_train, y_train, params, num_boost_round, early_stopping_rounds, verbose, trial)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             oof = self.model_1.predict(self.X_train[int(self.X_train.shape[0] / 2):],\n\u001b[1;32m---> 33\u001b[1;33m                                        num_iteration=self.model_1.best_iteration)\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0moof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\kaggle\\ashrae~1\\venv~1\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   2363\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[0;32m   2364\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2365\u001b[1;33m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[0;32m   2366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2367\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\kaggle\\ashrae~1\\venv~1\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\kaggle\\ashrae~1\\venv~1\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[1;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\kaggle\\ashrae~1\\venv~1\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[1;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong length for predict results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# Data Loading\n",
    "with open(train_pkl_path, 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "importance_df = pd.read_csv(importance_path)\n",
    "\n",
    "pruner = optuna.pruners.SuccessiveHalvingPruner(min_resource=50)\n",
    "\n",
    "# New Study\n",
    "study = optuna.create_study(\n",
    "    study_name='ashrae_lgb',\n",
    "    storage='sqlite:///ashrae_lgb.db',\n",
    "    load_if_exists=True,\n",
    "    direction='minimize',\n",
    "    pruner=pruner\n",
    ")\n",
    "\n",
    "# Reload Intermediate state\n",
    "# study = optuna.load_study(\n",
    "#     study_name='ashrae_lgb',\n",
    "#     storage='sqlite:///ashrae_lgb.db',\n",
    "#     pruner=pruner\n",
    "# )\n",
    "\n",
    "study.optimize(objective, timeout=60*60*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
