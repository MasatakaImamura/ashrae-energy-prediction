{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imamuramasataka/Documents/kaggle/ashrae-energy-prediction/.venv/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import random\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import optuna\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "myfavouritenumber = 0\n",
    "seed = myfavouritenumber\n",
    "random.seed(seed)\n",
    "\n",
    "pd.set_option('max_rows', 9999)\n",
    "pd.set_option('max_columns', 9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half_Half_LightGBM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, importance_df, model_type='lgb', use_feature_num=None):\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if use_feature_num is not None:\n",
    "            self.features = importance_df['feature'][:feature_num].tolist()\n",
    "        else:\n",
    "            self.features = None\n",
    "            \n",
    "    def train_half_optuna(self, X_train, y_train, params, num_boost_round, early_stopping_rounds, verbose=200, trial=None):\n",
    "        \n",
    "        if self.features is None:\n",
    "            self.features = X_train.columns\n",
    "            \n",
    "        self.features = [c for c in self.features if c not in ['M']]\n",
    "            \n",
    "        self.X_train = X_train[self.features]\n",
    "        self.y_train = y_train\n",
    "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'rmse')\n",
    "        \n",
    "        if self.model_type == 'lgb':\n",
    "            d_half_1 = lgb.Dataset(self.X_train[:int(self.X_train.shape[0] / 2)], \n",
    "                                   label=self.y_train[:int(X_train.shape[0] / 2)])\n",
    "            d_half_2 = lgb.Dataset(self.X_train[int(self.X_train.shape[0] / 2):], \n",
    "                                   label=self.y_train[int(X_train.shape[0] / 2):])\n",
    "\n",
    "            self.model_1 = lgb.train(params, train_set=d_half_1, num_boost_round=num_boost_round, \n",
    "                                     valid_sets=[d_half_2], verbose_eval=verbose, \n",
    "                                     early_stopping_rounds=early_stopping_rounds, \n",
    "                                     callbacks=[pruning_callback])\n",
    "            \n",
    "            oof = self.model_1.predict(self.X_train[int(self.X_train.shape[0] / 2):],\n",
    "                                       num_iteration=self.model_1.best_iteration)\n",
    "            \n",
    "            rmse = np.sqrt(mean_squared_error(self.y_train[int(X_train.shape[0] / 2):], oof))\n",
    "            \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "train_pkl_path = '../input/prep_train_20191118.pkl'\n",
    "test_pkl_path = '../input/prep_test_20191118.pkl'\n",
    "importance_path = '../Importance/importance_20191118.csv'\n",
    "model_type = 'lgb'\n",
    "\n",
    "# Create SQLite Table\n",
    "con = sqlite3.connect('ashrae_lgb.db')\n",
    "\n",
    "def objective(trial):\n",
    "    # Search Parameter Range\n",
    "    set_lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'boosting_type': 'gbrt',\n",
    "        'metric': 'rmse',\n",
    "        'n_jobs': -1,\n",
    "        'learning_rate': 0.01,\n",
    "        'max_bin': 255,\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 8),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 200),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 0.9),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 0.9),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.3, 0.9),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.3, 0.9),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 20),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-2, 1e+3),\n",
    "        'verbose': -1,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    num_boost_round = 500\n",
    "    early_stopping_rounds = 50\n",
    "    num_feature = None\n",
    "    verbose = False\n",
    "    \n",
    "    # Train Model\n",
    "    trainer = Trainer(importance_df=importance_df, model_type=model_type, use_feature_num=num_feature)\n",
    "    rmse = trainer.train_half_optuna(train[0], train[1], set_lgb_params, num_boost_round, \n",
    "                                       early_stopping_rounds, verbose, trial)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-11-18 15:12:36,641] Using an existing study with name 'ashrae_lgb' instead of creating a new one.\n",
      "[I 2019-11-18 15:25:14,611] Finished trial#7 resulted in value: 1.358166369237579. Current best value is 1.358166369237579 with parameters: {'bagging_fraction': 0.679651512314768, 'bagging_freq': 5, 'colsample_bytree': 0.6470667583544704, 'feature_fraction': 0.8076645109502967, 'max_depth': 5, 'min_data_in_leaf': 33, 'num_leaves': 20, 'reg_lambda': 6.627668083305644, 'subsample': 0.8367722515913292}.\n",
      "[I 2019-11-18 15:38:15,949] Finished trial#8 resulted in value: 1.3719347956545194. Current best value is 1.358166369237579 with parameters: {'bagging_fraction': 0.679651512314768, 'bagging_freq': 5, 'colsample_bytree': 0.6470667583544704, 'feature_fraction': 0.8076645109502967, 'max_depth': 5, 'min_data_in_leaf': 33, 'num_leaves': 20, 'reg_lambda': 6.627668083305644, 'subsample': 0.8367722515913292}.\n",
      "[I 2019-11-18 15:49:59,609] Finished trial#9 resulted in value: 1.3268459956873593. Current best value is 1.3268459956873593 with parameters: {'bagging_fraction': 0.5458069009118942, 'bagging_freq': 15, 'colsample_bytree': 0.7086036421969533, 'feature_fraction': 0.5393671390088924, 'max_depth': 6, 'min_data_in_leaf': 11, 'num_leaves': 189, 'reg_lambda': 0.01219653130460788, 'subsample': 0.808131030208829}.\n",
      "[I 2019-11-18 16:06:04,279] Finished trial#10 resulted in value: 1.3045638827203736. Current best value is 1.3045638827203736 with parameters: {'bagging_fraction': 0.42033302608317047, 'bagging_freq': 2, 'colsample_bytree': 0.6354266208820126, 'feature_fraction': 0.4825594344749637, 'max_depth': 7, 'min_data_in_leaf': 12, 'num_leaves': 198, 'reg_lambda': 0.01988735636673029, 'subsample': 0.7425715581103456}.\n",
      "[I 2019-11-18 16:22:00,338] Finished trial#11 resulted in value: 1.2501536473590762. Current best value is 1.2501536473590762 with parameters: {'bagging_fraction': 0.5698208841433416, 'bagging_freq': 11, 'colsample_bytree': 0.7980989858789092, 'feature_fraction': 0.57898778319507, 'max_depth': 8, 'min_data_in_leaf': 22, 'num_leaves': 94, 'reg_lambda': 146.63931177112744, 'subsample': 0.7571786935948946}.\n",
      "[I 2019-11-18 16:30:41,559] Finished trial#12 resulted in value: 1.4151697637206364. Current best value is 1.2501536473590762 with parameters: {'bagging_fraction': 0.5698208841433416, 'bagging_freq': 11, 'colsample_bytree': 0.7980989858789092, 'feature_fraction': 0.57898778319507, 'max_depth': 8, 'min_data_in_leaf': 22, 'num_leaves': 94, 'reg_lambda': 146.63931177112744, 'subsample': 0.7571786935948946}.\n",
      "[I 2019-11-18 16:45:06,351] Finished trial#13 resulted in value: 1.283221752198317. Current best value is 1.2501536473590762 with parameters: {'bagging_fraction': 0.5698208841433416, 'bagging_freq': 11, 'colsample_bytree': 0.7980989858789092, 'feature_fraction': 0.57898778319507, 'max_depth': 8, 'min_data_in_leaf': 22, 'num_leaves': 94, 'reg_lambda': 146.63931177112744, 'subsample': 0.7571786935948946}.\n",
      "[I 2019-11-18 16:53:27,239] Finished trial#14 resulted in value: 1.4233529067859896. Current best value is 1.2501536473590762 with parameters: {'bagging_fraction': 0.5698208841433416, 'bagging_freq': 11, 'colsample_bytree': 0.7980989858789092, 'feature_fraction': 0.57898778319507, 'max_depth': 8, 'min_data_in_leaf': 22, 'num_leaves': 94, 'reg_lambda': 146.63931177112744, 'subsample': 0.7571786935948946}.\n",
      "[I 2019-11-18 17:03:58,413] Finished trial#15 resulted in value: 1.4214503456887124. Current best value is 1.2501536473590762 with parameters: {'bagging_fraction': 0.5698208841433416, 'bagging_freq': 11, 'colsample_bytree': 0.7980989858789092, 'feature_fraction': 0.57898778319507, 'max_depth': 8, 'min_data_in_leaf': 22, 'num_leaves': 94, 'reg_lambda': 146.63931177112744, 'subsample': 0.7571786935948946}.\n",
      "[I 2019-11-18 17:19:21,779] Finished trial#16 resulted in value: 1.3384853852373582. Current best value is 1.2501536473590762 with parameters: {'bagging_fraction': 0.5698208841433416, 'bagging_freq': 11, 'colsample_bytree': 0.7980989858789092, 'feature_fraction': 0.57898778319507, 'max_depth': 8, 'min_data_in_leaf': 22, 'num_leaves': 94, 'reg_lambda': 146.63931177112744, 'subsample': 0.7571786935948946}.\n",
      "[I 2019-11-18 17:35:26,172] Finished trial#17 resulted in value: 1.289199305519266. Current best value is 1.2501536473590762 with parameters: {'bagging_fraction': 0.5698208841433416, 'bagging_freq': 11, 'colsample_bytree': 0.7980989858789092, 'feature_fraction': 0.57898778319507, 'max_depth': 8, 'min_data_in_leaf': 22, 'num_leaves': 94, 'reg_lambda': 146.63931177112744, 'subsample': 0.7571786935948946}.\n",
      "[I 2019-11-18 17:47:54,318] Finished trial#18 resulted in value: 1.3240686401010284. Current best value is 1.2501536473590762 with parameters: {'bagging_fraction': 0.5698208841433416, 'bagging_freq': 11, 'colsample_bytree': 0.7980989858789092, 'feature_fraction': 0.57898778319507, 'max_depth': 8, 'min_data_in_leaf': 22, 'num_leaves': 94, 'reg_lambda': 146.63931177112744, 'subsample': 0.7571786935948946}.\n",
      "[I 2019-11-18 18:02:32,664] Finished trial#19 resulted in value: 1.313032671504084. Current best value is 1.2501536473590762 with parameters: {'bagging_fraction': 0.5698208841433416, 'bagging_freq': 11, 'colsample_bytree': 0.7980989858789092, 'feature_fraction': 0.57898778319507, 'max_depth': 8, 'min_data_in_leaf': 22, 'num_leaves': 94, 'reg_lambda': 146.63931177112744, 'subsample': 0.7571786935948946}.\n",
      "[I 2019-11-18 18:23:31,280] Finished trial#20 resulted in value: 1.2120604643812445. Current best value is 1.2120604643812445 with parameters: {'bagging_fraction': 0.745484957080361, 'bagging_freq': 13, 'colsample_bytree': 0.8849580581424049, 'feature_fraction': 0.8929842171475193, 'max_depth': 8, 'min_data_in_leaf': 33, 'num_leaves': 128, 'reg_lambda': 120.01459150250875, 'subsample': 0.7988878056225179}.\n",
      "[I 2019-11-18 18:41:37,185] Finished trial#21 resulted in value: 1.2107727473767167. Current best value is 1.2107727473767167 with parameters: {'bagging_fraction': 0.7653206493513004, 'bagging_freq': 14, 'colsample_bytree': 0.8982551907403393, 'feature_fraction': 0.8428758406416235, 'max_depth': 8, 'min_data_in_leaf': 34, 'num_leaves': 97, 'reg_lambda': 149.04596254175257, 'subsample': 0.794921578739811}.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# Data Loading\n",
    "with open(train_pkl_path, 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "importance_df = pd.read_csv(importance_path)\n",
    "\n",
    "pruner = optuna.pruners.SuccessiveHalvingPruner(min_resource=500)\n",
    "study = optuna.create_study(\n",
    "    study_name='ashrae_lgb',\n",
    "    storage='sqlite:///ashrae_lgb.db',\n",
    "    load_if_exists=True,\n",
    "    direction='minimize',\n",
    "    pruner=pruner\n",
    ")\n",
    "\n",
    "# Reload Intermediate state\n",
    "# study = optuna.load_study(\n",
    "#     study_name='ashrae_lgb',\n",
    "#     storage='sqlite:///ashrae_lgb.db',\n",
    "#     pruner=pruner\n",
    "# )\n",
    "\n",
    "study.optimize(objective, timeout=60*60*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
